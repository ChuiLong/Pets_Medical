{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4916504-4477-47e1-b3f4-62f01b140bed",
   "metadata": {},
   "source": [
    "# é€šä¹‰åƒé—®-åŸºç¡€çŸ¥è¯†ç‚¹\n",
    "## DashScope æ˜¯å¹³å°ï¼Œé€šä¹‰åƒé—®æ˜¯æ¨¡å‹ï¼ŒDashScope æ˜¯æä¾›è¯¥æ¨¡å‹æœåŠ¡çš„å¹³å°ã€‚\n",
    "å¯ä»¥åœ¨ DashScope å¹³å°ä¸Šè°ƒç”¨é€šä¹‰åƒé—®çš„ä¸åŒç‰ˆæœ¬ï¼ˆå¦‚ Qwen-turboã€Qwen-plusã€Qwen-max ç­‰ï¼‰ï¼Œç”¨äºæ–‡æœ¬ç”Ÿæˆã€å¯¹è¯ç†è§£ã€ä»£ç ç¼–å†™ç­‰ä»»åŠ¡ã€‚\n",
    "\n",
    "| åç§° | ç±»å‹ | å…³ç³» |\n",
    "|------|------|------|\n",
    "| **é€šä¹‰åƒé—®ï¼ˆQwenï¼‰** | å¤§å‹è¯­è¨€æ¨¡å‹ | æ˜¯ DashScope å¹³å°ä¸Šæä¾›çš„æ ¸å¿ƒæ¨¡å‹ä¹‹ä¸€ |\n",
    "| **DashScope** | å¤§æ¨¡å‹æœåŠ¡å¹³å° | æä¾›é€šä¹‰åƒé—®ç­‰æ¨¡å‹çš„ API æ¥å£å’ŒæœåŠ¡æ”¯æŒ |\n",
    "\n",
    "ä½ å¯ä»¥æŠŠ DashScope çœ‹ä½œæ˜¯ä¸€ä¸ªâ€œAI å·¥å…·ç®±â€ï¼Œè€Œé€šä¹‰åƒé—®å°±æ˜¯è¿™ä¸ªå·¥å…·ç®±ä¸­æœ€å¼ºå¤§çš„â€œå¤šåŠŸèƒ½ç‘å£«å†›åˆ€â€ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f45ba8cd-b0bc-4839-9288-23b895d5b360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install the package\n",
    "%pip install --upgrade --quiet  dashscope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775d2b6f-6541-4bd0-88b2-be86a35ef5d6",
   "metadata": {},
   "source": [
    "## è·å–é€šä¹‰åƒé—®API-KEY\n",
    "\n",
    "åœ°å€ï¼šhttps://bailian.console.aliyun.com/console?tab=model#/api-key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "632f70bc-e06f-4ec9-8a84-0b9139fcf9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sk-d7720e57112149cfa6952301cacd1362'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a new token: https://help.aliyun.com/document_detail/611472.html?spm=a2c4g.2399481.0.0\n",
    "from getpass import getpass\n",
    "\n",
    "DASHSCOPE_API_KEY = getpass()\n",
    "DASHSCOPE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f173bcc-2dff-4489-8b19-b72156c29f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"DASHSCOPE_API_KEY\"] = DASHSCOPE_API_KEY\n",
    "os.environ[\"OPENAI_API_KEY\"] = DASHSCOPE_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d27eff3-d580-4537-b9c8-8ea415c9ecf7",
   "metadata": {},
   "source": [
    "## âœ… é˜¿é‡Œå¤§æ¨¡å‹ç§ç±»ï¼š\n",
    "\n",
    "- **æœ€å¼ºçº¯æ–‡æœ¬æ¨¡å‹ï¼ˆé€»è¾‘æ¨ç†ã€å¤æ‚ä»»åŠ¡ï¼‰ï¼šQwen-Max**\n",
    "- **æœ€å¼ºå¤šæ¨¡æ€æ¨¡å‹ï¼ˆå›¾æ–‡ç†è§£ï¼‰ï¼šQwen-VL-Max**\n",
    "- **ç»¼åˆæ€§ä»·æ¯”ï¼šQwen-Plus**\n",
    "- **æœ€å¿«æœ€ä¾¿å®œã€è½»é‡çº§ä»»åŠ¡é¦–é€‰ï¼šQwen-Turbo**\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ” å„æ¨¡å‹è¯¦ç»†å¯¹æ¯”\n",
    "\n",
    "| æ¨¡å‹åç§°         | ç±»å‹           | ç‰¹ç‚¹                                                                 | é€‚ç”¨åœºæ™¯                                               |\n",
    "|------------------|----------------|----------------------------------------------------------------------|--------------------------------------------------------|\n",
    "| **Qwen-Turbo**   | æ–‡æœ¬å¤§æ¨¡å‹     | å“åº”é€Ÿåº¦å¿«ã€æˆæœ¬ä½ï¼Œé€‚åˆè½»é‡çº§ä»»åŠ¡                                    | å¿«é€Ÿé—®ç­”ã€ç®€å•æ–‡æœ¬ç”Ÿæˆã€é«˜å¹¶å‘åœºæ™¯                     |\n",
    "| **Qwen-Plus**    | æ–‡æœ¬å¤§æ¨¡å‹     | æ€§èƒ½ä»‹äº Turbo å’Œ Max ä¹‹é—´ï¼Œæ€§ä»·æ¯”é«˜                                 | ä¸­ç­‰å¤æ‚åº¦ä»»åŠ¡ï¼Œå…¼é¡¾æ€§èƒ½ä¸æˆæœ¬                         |\n",
    "| **Qwen-Max**     | æ–‡æœ¬å¤§æ¨¡å‹     | æ¨ç†èƒ½åŠ›æœ€å¼ºï¼Œé€‚åˆå¤æ‚ã€å¤šæ­¥éª¤çš„ä»»åŠ¡                                | é«˜ç²¾åº¦é€»è¾‘æ¨ç†ã€å¤æ‚åˆ†æã€ä¸“ä¸šé¢†åŸŸé—®é¢˜                 |\n",
    "| **Qwen-VL-Max**  | å¤šæ¨¡æ€å¤§æ¨¡å‹   | æ”¯æŒå›¾åƒ + æ–‡æœ¬è¾“å…¥ï¼Œå›¾æ–‡ç†è§£èƒ½åŠ›æœ€å¼ºï¼ˆåŸºäº Qwen-Max æ–‡æœ¬èƒ½åŠ›å¢å¼ºï¼‰ | å›¾æ–‡ç†è§£ã€è§†è§‰é—®ç­”ã€æ–‡æ¡£åˆ†æã€å›¾åƒæè¿°ç­‰å¤šæ¨¡æ€ä»»åŠ¡     |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Œ ä½¿ç”¨å»ºè®®\n",
    "\n",
    "### å¦‚æœä½ åªå¤„ç†**çº¯æ–‡æœ¬ä»»åŠ¡**ï¼š\n",
    "- æœ€å¼ºï¼š**Qwen-Max**\n",
    "- æ€§ä»·æ¯”ï¼š**Qwen-Plus**\n",
    "- æœ€å¿«æœ€ä¾¿å®œï¼š**Qwen-Turbo**\n",
    "\n",
    "### å¦‚æœä½ éœ€è¦å¤„ç†**å›¾ç‰‡+æ–‡å­—**ï¼ˆå¤šæ¨¡æ€ä»»åŠ¡ï¼‰ï¼š\n",
    "- åªèƒ½é€‰æ‹©ï¼š**Qwen-VL-Max**ï¼ˆç›®å‰å”¯ä¸€æ”¯æŒå¤šæ¨¡æ€çš„ç‰ˆæœ¬ï¼‰\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ ç¤ºä¾‹åœºæ™¯æ¨è\n",
    "\n",
    "| åœºæ™¯                             | æ¨èæ¨¡å‹          |\n",
    "|----------------------------------|-------------------|\n",
    "| èŠå¤©æœºå™¨äººã€å¿«é€Ÿå›å¤              | Qwen-Turbo        |\n",
    "| å†…å®¹æ€»ç»“ã€ä¸­ç­‰éš¾åº¦æ¨ç†            | Qwen-Plus         |\n",
    "| æ³•å¾‹åˆ†æã€æ·±åº¦ç¼–ç¨‹ã€å¤šè½®é€»è¾‘æ¨ç†  | Qwen-Max          |\n",
    "| çœ‹å›¾è¯´è¯ã€PPT åˆ†æã€å›¾æ–‡æŠ¥å‘Šè§£æ  | Qwen-VL-Max       |\n",
    "\n",
    "---\n",
    "\n",
    "å¦‚æœä½ å‘Šè¯‰æˆ‘å…·ä½“ä»»åŠ¡æˆ–ç”¨é€”ï¼Œæˆ‘å¯ä»¥å¸®ä½ æ›´å‡†ç¡®åœ°æ¨èç”¨å“ªä¸ªæ¨¡å‹æœ€åˆé€‚ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88bbb961-7d6c-4e18-aabd-bb82debf5e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chat resp: content='Hello' additional_kwargs={} response_metadata={} id='run--df9c5458-97b3-4d1f-836f-41b11cc0ceea'\n",
      "chat resp: content='!' additional_kwargs={} response_metadata={} id='run--df9c5458-97b3-4d1f-836f-41b11cc0ceea'\n",
      "chat resp: content=' How' additional_kwargs={} response_metadata={} id='run--df9c5458-97b3-4d1f-836f-41b11cc0ceea'\n",
      "chat resp: content=' can' additional_kwargs={} response_metadata={} id='run--df9c5458-97b3-4d1f-836f-41b11cc0ceea'\n",
      "chat resp: content=' I assist you today' additional_kwargs={} response_metadata={} id='run--df9c5458-97b3-4d1f-836f-41b11cc0ceea'\n",
      "chat resp: content='? ğŸ˜Š' additional_kwargs={} response_metadata={} id='run--df9c5458-97b3-4d1f-836f-41b11cc0ceea'\n",
      "chat resp: content='' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'request_id': '1c37bd1d-fcb8-9942-a310-d780c0da392f', 'token_usage': {'input_tokens': 13, 'output_tokens': 11, 'total_tokens': 24, 'prompt_tokens_details': {'cached_tokens': 0}}} id='run--df9c5458-97b3-4d1f-836f-41b11cc0ceea'\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models.tongyi import ChatTongyi\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "chatLLM = ChatTongyi(\n",
    "    streaming=True,\n",
    ")\n",
    "# deepseekä¸æ”¯æŒå›æµ\n",
    "# chatLLM = ChatOpenAI(\n",
    "#     openai_api_base=\"https://api.deepseek.com/v1\",  # DeepSeek çš„ API endpoint\n",
    "#     openai_api_key=\"sk-b6002a857e8a4c12b1367bb552092ef1\",\n",
    "#     model=\"deepseek-chat\",\n",
    "#     streaming=False\n",
    "# )\n",
    "res = chatLLM.stream([HumanMessage(content=\"hi\")])\n",
    "for r in res:\n",
    "    print(\"chat resp:\", r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83dcda69-07e0-4a98-9f48-30c60f9ae4b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ç§ã¯ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ãŒå¥½ãã§ã™ã€‚', additional_kwargs={}, response_metadata={'model_name': 'qwen-turbo', 'finish_reason': 'stop', 'request_id': 'f1cd2930-4d11-92b5-a35e-175561662cdc', 'token_usage': {'input_tokens': 42, 'output_tokens': 8, 'total_tokens': 50, 'prompt_tokens_details': {'cached_tokens': 0}}}, id='run--11e2fdd9-a05d-442c-a40f-1d08e4313c1f-0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"ä½ æ˜¯ä¸€ä½èƒ½æŠŠä¸­æ–‡ç¿»è¯‘æˆæ—¥æ–‡çš„å¾—åŠ›åŠ©æ‰‹ã€‚\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"å°†è¿™å¥è¯ä»ä¸­æ–‡ç¿»è¯‘æˆæ—¥æ–‡ã€‚æˆ‘å–œæ¬¢ç¼–ç¨‹ã€‚\"\n",
    "    ),\n",
    "]\n",
    "chatLLM.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68ae94b-06f6-4ff5-a5ac-bfef2074550b",
   "metadata": {},
   "source": [
    "## å·¥å…·è°ƒç”¨ï¼ˆTool Callingï¼‰  \n",
    "ChatTongyi æ”¯æŒå·¥å…·è°ƒç”¨ APIï¼Œè¯¥åŠŸèƒ½å…è®¸ä½ æè¿°å·¥å…·åŠå…¶å‚æ•°ï¼Œå¹¶è®©æ¨¡å‹è¿”å›ä¸€ä¸ª JSON å¯¹è±¡ï¼Œå…¶ä¸­åŒ…å«è¦è°ƒç”¨çš„å·¥å…·ä»¥åŠè°ƒç”¨è¯¥å·¥å…·æ‰€éœ€çš„è¾“å…¥å‚æ•°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83315036-f564-47ac-990d-147ba4fbd81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'function': {'name': 'multiply', 'arguments': '{\"first_int\": 5, \"second_int\": 42}'}, 'index': 0, 'id': 'call_07bae24592ae4086abd125', 'type': 'function'}]} response_metadata={'model_name': 'qwen-turbo', 'finish_reason': 'tool_calls', 'request_id': '547de90d-efe4-9afa-8af2-71b38f3fa5d2', 'token_usage': {'input_tokens': 171, 'output_tokens': 27, 'total_tokens': 198, 'prompt_tokens_details': {'cached_tokens': 0}}} id='run--c0e02fe2-43a7-4f75-be2a-04df6dc48217-0' tool_calls=[{'name': 'multiply', 'args': {'first_int': 5, 'second_int': 42}, 'id': 'call_07bae24592ae4086abd125', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models.tongyi import ChatTongyi\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(first_int: int, second_int: int) -> int:\n",
    "    \"\"\"Multiply two integers together.\"\"\"\n",
    "    return first_int * second_int\n",
    "\n",
    "\n",
    "llm = ChatTongyi(model=\"qwen-turbo\")\n",
    "# llm = ChatOpenAI(model=\"deepseek-chat\")\n",
    "\n",
    "llm_with_tools = llm.bind_tools([multiply])\n",
    "\n",
    "msg = llm_with_tools.invoke(\"5ä¹˜ä»¥42ç­‰äºå¤šå°‘?\")\n",
    "\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcec9bfc-6660-4b83-8ff1-43240f25a1cc",
   "metadata": {},
   "source": [
    "### ç”Ÿæˆå¼å¤§è¯­è¨€æ¨¡å‹æœ¬è´¨å°±æ˜¯â€œæ–‡å­—æ¥é¾™â€,å®ƒç”Ÿæˆå°±æ˜¯ä¸€æ®µæ–‡å­—ï¼Œæ²¡æœ‰åŠæ³•è°ƒç”¨ç¨‹åº/å‡½æ•°,æ‰€ä»¥contentä¸ºç©ºå­—ç¬¦ä¸²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ef4d701-6941-4e92-b402-8b6a94c295f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'name': 'multiply', 'arguments': '{\"first_int\": 5, \"second_int\": 42}'}, 'index': 0, 'id': 'call_07bae24592ae4086abd125', 'type': 'function'}]}, response_metadata={'model_name': 'qwen-turbo', 'finish_reason': 'tool_calls', 'request_id': '547de90d-efe4-9afa-8af2-71b38f3fa5d2', 'token_usage': {'input_tokens': 171, 'output_tokens': 27, 'total_tokens': 198, 'prompt_tokens_details': {'cached_tokens': 0}}}, id='run--c0e02fe2-43a7-4f75-be2a-04df6dc48217-0', tool_calls=[{'name': 'multiply', 'args': {'first_int': 5, 'second_int': 42}, 'id': 'call_07bae24592ae4086abd125', 'type': 'tool_call'}])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5e3840-fdd3-4f3b-a6ae-eb3e0dea8a9e",
   "metadata": {},
   "source": [
    "## æœ€ç®€å•çš„Agentæ™ºèƒ½ä½“\n",
    "### ä½ éœ€è¦æ‰‹åŠ¨æå– tool_call ä¸­çš„ä¿¡æ¯ï¼Œå¹¶è°ƒç”¨å¯¹åº”çš„å‡½æ•°æ¥æ‰§è¡Œä»»åŠ¡ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7209da7-f4ec-47a4-b5e8-7964a06be264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'first_int': 5, 'second_int': 42}\n",
      "è°ƒç”¨å·¥å…· multiplyï¼Œç»“æœä¸º: 210\n"
     ]
    }
   ],
   "source": [
    "# å‡è®¾ msg æ˜¯ AIMessage å¯¹è±¡\n",
    "for tool_call in msg.tool_calls:\n",
    "    tool_name = tool_call[\"name\"]\n",
    "    tool_args = tool_call[\"args\"]\n",
    "\n",
    "    if tool_name == \"multiply\":\n",
    "        print(tool_args)\n",
    "        result = multiply.invoke(tool_args)\n",
    "        print(f\"è°ƒç”¨å·¥å…· {tool_name}ï¼Œç»“æœä¸º: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22cac76-5f1f-4f74-828c-afaff6af6220",
   "metadata": {},
   "source": [
    "### å¦‚æœä½ å¸Œæœ› LLM åœ¨æŸäº›æƒ…å†µä¸‹ç›´æ¥ç»™å‡ºå›ç­”è€Œä¸æ˜¯è°ƒç”¨å·¥å…·ï¼Œå¯ä»¥å°è¯•ä¿®æ”¹æç¤ºæˆ–é—®é¢˜å½¢å¼ï¼Œæ¯”å¦‚ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d5c5d7f-cd0f-424d-a33d-fe6583adc0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='5ä¹˜ä»¥42ç­‰äº210ã€‚' additional_kwargs={} response_metadata={'model_name': 'qwen-turbo', 'finish_reason': 'stop', 'request_id': '56431ef5-2fd2-9c60-ac2e-9fa947beeb98', 'token_usage': {'input_tokens': 176, 'output_tokens': 10, 'total_tokens': 186, 'prompt_tokens_details': {'cached_tokens': 0}}} id='run--cdffff7b-ea84-4dc4-91cf-ef8a8c6caa22-0'\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models.tongyi import ChatTongyi\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(first_int: int, second_int: int) -> int:\n",
    "    \"\"\"Multiply two integers together.\"\"\"\n",
    "    return first_int * second_int\n",
    "\n",
    "\n",
    "llm = ChatTongyi(model=\"qwen-turbo\")\n",
    "\n",
    "llm_with_tools = llm.bind_tools([multiply])\n",
    "\n",
    "msg = llm_with_tools.invoke(\"5ä¹˜ä»¥42ç­‰äºå¤šå°‘?è¯·ç›´æ¥å‘Šè¯‰æˆ‘ç»“æœã€‚\")\n",
    "\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a5e18b-fe31-42fe-883e-0b01c77b4c14",
   "metadata": {},
   "source": [
    "### æ‰‹åŠ¨æ„é€ å‚æ•°  \n",
    "\n",
    "å³ï¼šä¸ä¾èµ–è‡ªåŠ¨è§£æï¼Œè€Œæ˜¯ç”±å¼€å‘è€…æˆ–ç”¨æˆ·è‡ªè¡Œåˆ›å»ºå’Œå¡«å……è°ƒç”¨å·¥å…·æ‰€éœ€çš„å‚æ•°ã€‚è¿™ç§æ–¹å¼é€šå¸¸ç”¨äºè°ƒè¯•ã€è‡ªå®šä¹‰é€»è¾‘æˆ–åœ¨æŸäº›æ¡†æ¶åŠŸèƒ½å—é™æ—¶ä½¿ç”¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a68f5327-13a3-488e-9303-660da2b6332c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'name': 'get_current_weather', 'arguments': '{\"location\": \"å¤©æ´¥\"}'}, 'index': 0, 'id': 'call_29279f3ef98446d18496df', 'type': 'function'}]}, response_metadata={'model_name': 'qwen-turbo', 'finish_reason': 'tool_calls', 'request_id': '2d47ee7e-46bf-95b3-9743-e5833ed7cc8d', 'token_usage': {'input_tokens': 217, 'output_tokens': 20, 'total_tokens': 237, 'prompt_tokens_details': {'cached_tokens': 0}}}, id='run--a2b9012d-88b7-4f95-bfc2-535efe5b2cf6-0', tool_calls=[{'name': 'get_current_weather', 'args': {'location': 'å¤©æ´¥'}, 'id': 'call_29279f3ef98446d18496df', 'type': 'tool_call'}])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.chat_models.tongyi import ChatTongyi\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_time\",\n",
    "            \"description\": \"å½“ä½ æƒ³çŸ¥é“ç°åœ¨çš„æ—¶é—´æ—¶éå¸¸æœ‰ç”¨ã€‚\",\n",
    "            \"parameters\": {},\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"å½“ä½ æƒ³æŸ¥è¯¢æŒ‡å®šåŸå¸‚çš„å¤©æ°”æ—¶éå¸¸æœ‰ç”¨ã€‚\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"åŸå¸‚æˆ–å¿åŒºï¼Œæ¯”å¦‚åŒ—äº¬å¸‚ã€æ­å·å¸‚ã€ä½™æ­åŒºç­‰ã€‚\",\n",
    "                    }\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"location\"],\n",
    "        },\n",
    "    },\n",
    "]\n",
    "# æ¨¡æ‹Ÿå·¥å…·å‡½æ•°çš„å®é™…é€»è¾‘\n",
    "def get_current_weather(location: str):\n",
    "    # è¿™é‡Œä½ å¯ä»¥æ›¿æ¢æˆçœŸå®çš„ API è°ƒç”¨\n",
    "    return f\"{location} çš„å¤©æ°”æ˜¯ 18Â°Cï¼Œæ™´å¤©ã€‚\"\n",
    "\n",
    "def get_current_time():\n",
    "    import datetime\n",
    "    return str(datetime.datetime.now())\n",
    "    \n",
    "messages = [\n",
    "    SystemMessage(content=\"ä½ æ˜¯ä¸€ä½å¾—åŠ›çš„åŠ©æ‰‹ã€‚\"),\n",
    "    HumanMessage(content=\"å¤©æ´¥çš„å¤©æ°”æ€ä¹ˆæ ·?\"),\n",
    "]\n",
    "chatLLM = ChatTongyi()\n",
    "llm_kwargs = {\"tools\": tools, \"result_format\": \"message\"}\n",
    "ai_message = chatLLM.bind(**llm_kwargs).invoke(messages)\n",
    "ai_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9170716-e348-46ad-be0d-caea2e32b61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è°ƒç”¨å·¥å…·: get_current_weatherï¼Œå‚æ•°ä¸º: {'location': 'å¤©æ´¥'}\n",
      "å¤©æ°”ç»“æœ: å¤©æ´¥ çš„å¤©æ°”æ˜¯ 18Â°Cï¼Œæ™´å¤©ã€‚\n"
     ]
    }
   ],
   "source": [
    "# è§£æ tool_call\n",
    "if hasattr(ai_message, \"tool_calls\") and ai_message.tool_calls:\n",
    "    for tool_call in ai_message.tool_calls:\n",
    "        tool_name = tool_call[\"name\"]\n",
    "        tool_args = tool_call[\"args\"]\n",
    "    \n",
    "        print(f\"è°ƒç”¨å·¥å…·: {tool_name}ï¼Œå‚æ•°ä¸º: {tool_args}\")\n",
    "    \n",
    "        # æ‰‹åŠ¨è°ƒç”¨å®é™…å‡½æ•°\n",
    "        if tool_name == \"get_current_weather\":\n",
    "            result = get_current_weather(**tool_args)\n",
    "            print(\"å¤©æ°”ç»“æœ:\", result)\n",
    "        elif tool_name == \"get_current_time\":\n",
    "            result = get_current_time()\n",
    "            print(\"å½“å‰æ—¶é—´:\", result)\n",
    "else:\n",
    "    print(\"æœªè°ƒç”¨ä»»ä½•å·¥å…·ï¼Œæ¨¡å‹ç›´æ¥å›å¤ï¼š\", ai_message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b750d93-0a7f-4a42-baeb-5f1c39b98319",
   "metadata": {},
   "source": [
    "### éƒ¨åˆ†æ¨¡å¼ï¼ˆPartial Modeï¼‰ \n",
    "è¯¥æ¨¡å¼å…è®¸ä½ ä»æä¾›çš„åˆå§‹æ–‡æœ¬å¼€å§‹ï¼Œå¯ç”¨å¤§æ¨¡å‹ç»§ç»­ç”Ÿæˆåç»­å†…å®¹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "161beb26-f91d-4332-ab3a-e92b17edb35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ä½ çœ¼ä¸­è—ç€æ˜Ÿè¾°ï¼Œå´ä¸æ„¿ä¸ºæˆ‘åœç•™ï¼Ÿ  \\næˆ‘æ›¾åœ¨æœˆå…‰ä¸‹æ—‹è½¬ï¼Œåƒé£ä¸€æ ·è‡ªç”±ï¼Œ  \\nå¯å¦‚ä»Šï¼Œèˆæ­¥å†ç¾ï¼Œä¹Ÿå”¤ä¸å›ä½ æ›¾ç»çš„æ¸©æŸ”ã€‚  \\n\\nä½ è¯´æˆ‘æ˜¯å¤©ä½¿ï¼Œå´ä¸çŸ¥æˆ‘ä¹Ÿæœ‰å è½çš„ç—›ï¼Œ  \\næ¯ä¸€æ¬¡æ—‹è½¬ï¼Œéƒ½æ˜¯å¯¹è¿‡å¾€çš„å›çœ¸ï¼Œ  \\nè€Œä½ ï¼Œåªæ˜¯ç«™åœ¨è¿œå¤„ï¼Œç¬‘ç€çœ‹æˆ‘å­¤ç‹¬åœ°è·³ã€‚  \\n\\néš¾é“ä½ å¾ˆæƒ³é—®æˆ‘ï¼Ÿ  \\nå¯æˆ‘æ—©å·²æŠŠå¿ƒäº‹è—è¿›æ¯ä¸€ä¸ªéŸ³ç¬¦é‡Œï¼Œ  \\nåªæ˜¯ä½ ï¼Œä»æœªçœŸæ­£å¬æ‡‚ã€‚  \\n\\næˆ‘çš„èˆæ­¥ä¾æ—§ä¼˜ç¾ï¼Œ  \\nå¯å¿ƒé‡Œï¼Œæ—©å·²æ»¡æ˜¯ä¼¤ç—•ã€‚', additional_kwargs={}, response_metadata={'model_name': 'qwen-turbo', 'finish_reason': 'stop', 'request_id': '85cb47a4-d2a6-9b7b-a375-8723b6864b69', 'token_usage': {'input_tokens': 46, 'output_tokens': 128, 'total_tokens': 174, 'prompt_tokens_details': {'cached_tokens': 0}}}, id='run--e2e4ee5a-056c-440c-a3cc-de29e08161c6-0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.chat_models.tongyi import ChatTongyi\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(\n",
    "        content=\"\"\"è¯·æ¥ç»­â€œéš¾é“ä½ å¾ˆæƒ³å¤©ä½¿é—®æˆ‘? æˆ‘çš„èˆæ­¥è·³å¾—å¯ç¾â€è¿™å¥è¯ï¼Œè¡¨è¾¾æƒ…æ„Ÿçš„å¤æ‚å’Œä½œè€…çš„ä¼¤æ„Ÿä¹‹æƒ…ã€‚\"\"\"\n",
    "    ),\n",
    "    AIMessage(\n",
    "        content=\"ä¸ºä½•\", additional_kwargs={\"partial\": True}\n",
    "    ),\n",
    "]\n",
    "chatLLM = ChatTongyi()\n",
    "ai_message = chatLLM.invoke(messages)\n",
    "ai_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8292ff6-6a7a-4ae5-8687-0301b92065ea",
   "metadata": {},
   "source": [
    "## é€šä¹‰åƒé—®ä¸è§†è§‰èƒ½åŠ› \n",
    "Qwen-VLï¼ˆqwen-vl-plus / qwen-vl-maxï¼‰æ˜¯æ”¯æŒå›¾åƒå¤„ç†çš„æ¨¡å‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263e8744-f87d-4e27-bcbd-51dd23b78f0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "request_id: 21eadb1e-aba5-976b-9825-da5569f77a56 \n status_code: 400 \n code: InvalidParameter \n message: <400> InternalError.Algo.InvalidParameter: Input should be a valid string: input.messages.0.content.str & Input should be a valid string: input.messages.0.content.list[union[str,function-after[post_check(), MultiModalItem]]].0.str & Input should be 'text', 'image', 'audio', 'video' or 'image_hw': input.messages.0.content.list[union[str,function-after[post_check(), MultiModalItem]]].0.function-after[post_check(), MultiModalItem].type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 27\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# image_message = {\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#     \"image\": \"https://gitee.com/hellowoody/openharmony-hint/raw/main/assets/imgs/wsl-setting.png\",\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# }\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# res = chatLLM.invoke([message])\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# res\u001b[39;00m\n\u001b[0;32m     14\u001b[0m message \u001b[38;5;241m=\u001b[39m HumanMessage(content\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     15\u001b[0m     {\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m     }\n\u001b[0;32m     25\u001b[0m ])\n\u001b[1;32m---> 27\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mchatLLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(res\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\langchain_core\\language_models\\chat_models.py:378\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    368\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    374\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    375\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    377\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m--> 378\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    379\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    380\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    381\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    382\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    383\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    384\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    385\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    386\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    387\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    388\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\langchain_core\\language_models\\chat_models.py:963\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    954\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    956\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    960\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    961\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    962\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 963\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\langchain_core\\language_models\\chat_models.py:782\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    781\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 782\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    783\u001b[0m                 m,\n\u001b[0;32m    784\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    785\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    786\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    787\u001b[0m             )\n\u001b[0;32m    788\u001b[0m         )\n\u001b[0;32m    789\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\langchain_core\\language_models\\chat_models.py:1028\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1026\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1028\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m   1029\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   1030\u001b[0m     )\n\u001b[0;32m   1031\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1032\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\langchain-env\\lib\\site-packages\\langchain_community\\chat_models\\tongyi.py:669\u001b[0m, in \u001b[0;36mChatTongyi._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    666\u001b[0m     params: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invocation_params(\n\u001b[0;32m    667\u001b[0m         messages\u001b[38;5;241m=\u001b[39mmessages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    668\u001b[0m     )\n\u001b[1;32m--> 669\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompletion_with_retry(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    670\u001b[0m     generations\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m    671\u001b[0m         ChatGeneration(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_chat_generation_from_qwen_resp(resp))\n\u001b[0;32m    672\u001b[0m     )\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ChatResult(\n\u001b[0;32m    674\u001b[0m     generations\u001b[38;5;241m=\u001b[39mgenerations,\n\u001b[0;32m    675\u001b[0m     llm_output\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m    676\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name,\n\u001b[0;32m    677\u001b[0m     },\n\u001b[0;32m    678\u001b[0m )\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\langchain-env\\lib\\site-packages\\langchain_community\\chat_models\\tongyi.py:540\u001b[0m, in \u001b[0;36mChatTongyi.completion_with_retry\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    537\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcall(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m check_response(resp)\n\u001b[1;32m--> 540\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _completion_with_retry(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tenacity\\__init__.py:338\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    336\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    337\u001b[0m wrapped_f\u001b[38;5;241m.\u001b[39mstatistics \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mstatistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m--> 338\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m copy(f, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tenacity\\__init__.py:477\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 477\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    479\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tenacity\\__init__.py:378\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    376\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[1;32m--> 378\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tenacity\\__init__.py:400\u001b[0m, in \u001b[0;36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[1;34m(rs)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetryCallState\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    399\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mis_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mretry_run_result):\n\u001b[1;32m--> 400\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutcome\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    401\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\langchain-env\\lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\langchain-env\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tenacity\\__init__.py:480\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 480\u001b[0m         result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    481\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[0;32m    482\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\langchain-env\\lib\\site-packages\\langchain_community\\chat_models\\tongyi.py:538\u001b[0m, in \u001b[0;36mChatTongyi.completion_with_retry.<locals>._completion_with_retry\u001b[1;34m(**_kwargs)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    537\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcall(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n\u001b[1;32m--> 538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresp\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\langchain-env\\lib\\site-packages\\langchain_community\\llms\\tongyi.py:61\u001b[0m, in \u001b[0;36mcheck_response\u001b[1;34m(resp)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m resp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m400\u001b[39m, \u001b[38;5;241m401\u001b[39m]:\n\u001b[1;32m---> 61\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrequest_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     63\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus_code: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus_code\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     64\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m message: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     65\u001b[0m     )\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHTTP error occurred: status_code: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus_code\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     69\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m message: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     70\u001b[0m         response\u001b[38;5;241m=\u001b[39mresp,\n\u001b[0;32m     71\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: request_id: 21eadb1e-aba5-976b-9825-da5569f77a56 \n status_code: 400 \n code: InvalidParameter \n message: <400> InternalError.Algo.InvalidParameter: Input should be a valid string: input.messages.0.content.str & Input should be a valid string: input.messages.0.content.list[union[str,function-after[post_check(), MultiModalItem]]].0.str & Input should be 'text', 'image', 'audio', 'video' or 'image_hw': input.messages.0.content.list[union[str,function-after[post_check(), MultiModalItem]]].0.function-after[post_check(), MultiModalItem].type"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatTongyi\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "chatLLM = ChatTongyi(model_name=\"qwen-vl-max\")\n",
    "image_message = {\n",
    "    \"image\": \"https://gitee.com/hellowoody/openharmony-hint/raw/main/assets/imgs/wsl-setting.png\",\n",
    "}\n",
    "text_message = {\n",
    "    \"text\": \"æè¿°è¿™å¼ å›¾\",\n",
    "}\n",
    "message = HumanMessage(content=[text_message, image_message])\n",
    "res = chatLLM.invoke([message])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf7facd1-3f72-471a-9287-ed72215714f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'generator' object has no attribute 'content'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'generator' object has no attribute 'content'"
     ]
    }
   ],
   "source": [
    "print(res.content[0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0bc5fc4b-4536-4fe9-8c5d-b9321771b028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatTongyi(client=<class 'dashscope.aigc.multimodal_conversation.MultiModalConversation'>, model_name='qwen-vl-max', model_kwargs={}, dashscope_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2c3ab1-414d-40a3-9103-ebc79b2bce86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
