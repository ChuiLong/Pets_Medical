{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4916504-4477-47e1-b3f4-62f01b140bed",
   "metadata": {},
   "source": [
    "# 通义千问-基础知识点\n",
    "## DashScope 是平台，通义千问是模型，DashScope 是提供该模型服务的平台。\n",
    "可以在 DashScope 平台上调用通义千问的不同版本（如 Qwen-turbo、Qwen-plus、Qwen-max 等），用于文本生成、对话理解、代码编写等任务。\n",
    "\n",
    "| 名称 | 类型 | 关系 |\n",
    "|------|------|------|\n",
    "| **通义千问（Qwen）** | 大型语言模型 | 是 DashScope 平台上提供的核心模型之一 |\n",
    "| **DashScope** | 大模型服务平台 | 提供通义千问等模型的 API 接口和服务支持 |\n",
    "\n",
    "你可以把 DashScope 看作是一个“AI 工具箱”，而通义千问就是这个工具箱中最强大的“多功能瑞士军刀”。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f45ba8cd-b0bc-4839-9288-23b895d5b360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install the package\n",
    "%pip install --upgrade --quiet  dashscope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775d2b6f-6541-4bd0-88b2-be86a35ef5d6",
   "metadata": {},
   "source": [
    "## 获取通义千问API-KEY\n",
    "\n",
    "地址：https://bailian.console.aliyun.com/console?tab=model#/api-key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "632f70bc-e06f-4ec9-8a84-0b9139fcf9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sk-d7720e57112149cfa6952301cacd1362'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a new token: https://help.aliyun.com/document_detail/611472.html?spm=a2c4g.2399481.0.0\n",
    "from getpass import getpass\n",
    "\n",
    "DASHSCOPE_API_KEY = getpass()\n",
    "DASHSCOPE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f173bcc-2dff-4489-8b19-b72156c29f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"DASHSCOPE_API_KEY\"] = DASHSCOPE_API_KEY\n",
    "os.environ[\"OPENAI_API_KEY\"] = DASHSCOPE_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d27eff3-d580-4537-b9c8-8ea415c9ecf7",
   "metadata": {},
   "source": [
    "## ✅ 阿里大模型种类：\n",
    "\n",
    "- **最强纯文本模型（逻辑推理、复杂任务）：Qwen-Max**\n",
    "- **最强多模态模型（图文理解）：Qwen-VL-Max**\n",
    "- **综合性价比：Qwen-Plus**\n",
    "- **最快最便宜、轻量级任务首选：Qwen-Turbo**\n",
    "\n",
    "---\n",
    "\n",
    "## 🔍 各模型详细对比\n",
    "\n",
    "| 模型名称         | 类型           | 特点                                                                 | 适用场景                                               |\n",
    "|------------------|----------------|----------------------------------------------------------------------|--------------------------------------------------------|\n",
    "| **Qwen-Turbo**   | 文本大模型     | 响应速度快、成本低，适合轻量级任务                                    | 快速问答、简单文本生成、高并发场景                     |\n",
    "| **Qwen-Plus**    | 文本大模型     | 性能介于 Turbo 和 Max 之间，性价比高                                 | 中等复杂度任务，兼顾性能与成本                         |\n",
    "| **Qwen-Max**     | 文本大模型     | 推理能力最强，适合复杂、多步骤的任务                                | 高精度逻辑推理、复杂分析、专业领域问题                 |\n",
    "| **Qwen-VL-Max**  | 多模态大模型   | 支持图像 + 文本输入，图文理解能力最强（基于 Qwen-Max 文本能力增强） | 图文理解、视觉问答、文档分析、图像描述等多模态任务     |\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 使用建议\n",
    "\n",
    "### 如果你只处理**纯文本任务**：\n",
    "- 最强：**Qwen-Max**\n",
    "- 性价比：**Qwen-Plus**\n",
    "- 最快最便宜：**Qwen-Turbo**\n",
    "\n",
    "### 如果你需要处理**图片+文字**（多模态任务）：\n",
    "- 只能选择：**Qwen-VL-Max**（目前唯一支持多模态的版本）\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 示例场景推荐\n",
    "\n",
    "| 场景                             | 推荐模型          |\n",
    "|----------------------------------|-------------------|\n",
    "| 聊天机器人、快速回复              | Qwen-Turbo        |\n",
    "| 内容总结、中等难度推理            | Qwen-Plus         |\n",
    "| 法律分析、深度编程、多轮逻辑推理  | Qwen-Max          |\n",
    "| 看图说话、PPT 分析、图文报告解析  | Qwen-VL-Max       |\n",
    "\n",
    "---\n",
    "\n",
    "如果你告诉我具体任务或用途，我可以帮你更准确地推荐用哪个模型最合适。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88bbb961-7d6c-4e18-aabd-bb82debf5e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chat resp: content='Hello' additional_kwargs={} response_metadata={} id='run--df9c5458-97b3-4d1f-836f-41b11cc0ceea'\n",
      "chat resp: content='!' additional_kwargs={} response_metadata={} id='run--df9c5458-97b3-4d1f-836f-41b11cc0ceea'\n",
      "chat resp: content=' How' additional_kwargs={} response_metadata={} id='run--df9c5458-97b3-4d1f-836f-41b11cc0ceea'\n",
      "chat resp: content=' can' additional_kwargs={} response_metadata={} id='run--df9c5458-97b3-4d1f-836f-41b11cc0ceea'\n",
      "chat resp: content=' I assist you today' additional_kwargs={} response_metadata={} id='run--df9c5458-97b3-4d1f-836f-41b11cc0ceea'\n",
      "chat resp: content='? 😊' additional_kwargs={} response_metadata={} id='run--df9c5458-97b3-4d1f-836f-41b11cc0ceea'\n",
      "chat resp: content='' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'request_id': '1c37bd1d-fcb8-9942-a310-d780c0da392f', 'token_usage': {'input_tokens': 13, 'output_tokens': 11, 'total_tokens': 24, 'prompt_tokens_details': {'cached_tokens': 0}}} id='run--df9c5458-97b3-4d1f-836f-41b11cc0ceea'\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models.tongyi import ChatTongyi\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "chatLLM = ChatTongyi(\n",
    "    streaming=True,\n",
    ")\n",
    "# deepseek不支持回流\n",
    "# chatLLM = ChatOpenAI(\n",
    "#     openai_api_base=\"https://api.deepseek.com/v1\",  # DeepSeek 的 API endpoint\n",
    "#     openai_api_key=\"sk-b6002a857e8a4c12b1367bb552092ef1\",\n",
    "#     model=\"deepseek-chat\",\n",
    "#     streaming=False\n",
    "# )\n",
    "res = chatLLM.stream([HumanMessage(content=\"hi\")])\n",
    "for r in res:\n",
    "    print(\"chat resp:\", r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83dcda69-07e0-4a98-9f48-30c60f9ae4b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='私はプログラミングが好きです。', additional_kwargs={}, response_metadata={'model_name': 'qwen-turbo', 'finish_reason': 'stop', 'request_id': 'f1cd2930-4d11-92b5-a35e-175561662cdc', 'token_usage': {'input_tokens': 42, 'output_tokens': 8, 'total_tokens': 50, 'prompt_tokens_details': {'cached_tokens': 0}}}, id='run--11e2fdd9-a05d-442c-a40f-1d08e4313c1f-0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"你是一位能把中文翻译成日文的得力助手。\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"将这句话从中文翻译成日文。我喜欢编程。\"\n",
    "    ),\n",
    "]\n",
    "chatLLM.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68ae94b-06f6-4ff5-a5ac-bfef2074550b",
   "metadata": {},
   "source": [
    "## 工具调用（Tool Calling）  \n",
    "ChatTongyi 支持工具调用 API，该功能允许你描述工具及其参数，并让模型返回一个 JSON 对象，其中包含要调用的工具以及调用该工具所需的输入参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83315036-f564-47ac-990d-147ba4fbd81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'function': {'name': 'multiply', 'arguments': '{\"first_int\": 5, \"second_int\": 42}'}, 'index': 0, 'id': 'call_07bae24592ae4086abd125', 'type': 'function'}]} response_metadata={'model_name': 'qwen-turbo', 'finish_reason': 'tool_calls', 'request_id': '547de90d-efe4-9afa-8af2-71b38f3fa5d2', 'token_usage': {'input_tokens': 171, 'output_tokens': 27, 'total_tokens': 198, 'prompt_tokens_details': {'cached_tokens': 0}}} id='run--c0e02fe2-43a7-4f75-be2a-04df6dc48217-0' tool_calls=[{'name': 'multiply', 'args': {'first_int': 5, 'second_int': 42}, 'id': 'call_07bae24592ae4086abd125', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models.tongyi import ChatTongyi\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(first_int: int, second_int: int) -> int:\n",
    "    \"\"\"Multiply two integers together.\"\"\"\n",
    "    return first_int * second_int\n",
    "\n",
    "\n",
    "llm = ChatTongyi(model=\"qwen-turbo\")\n",
    "# llm = ChatOpenAI(model=\"deepseek-chat\")\n",
    "\n",
    "llm_with_tools = llm.bind_tools([multiply])\n",
    "\n",
    "msg = llm_with_tools.invoke(\"5乘以42等于多少?\")\n",
    "\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcec9bfc-6660-4b83-8ff1-43240f25a1cc",
   "metadata": {},
   "source": [
    "### 生成式大语言模型本质就是“文字接龙”,它生成就是一段文字，没有办法调用程序/函数,所以content为空字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ef4d701-6941-4e92-b402-8b6a94c295f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'name': 'multiply', 'arguments': '{\"first_int\": 5, \"second_int\": 42}'}, 'index': 0, 'id': 'call_07bae24592ae4086abd125', 'type': 'function'}]}, response_metadata={'model_name': 'qwen-turbo', 'finish_reason': 'tool_calls', 'request_id': '547de90d-efe4-9afa-8af2-71b38f3fa5d2', 'token_usage': {'input_tokens': 171, 'output_tokens': 27, 'total_tokens': 198, 'prompt_tokens_details': {'cached_tokens': 0}}}, id='run--c0e02fe2-43a7-4f75-be2a-04df6dc48217-0', tool_calls=[{'name': 'multiply', 'args': {'first_int': 5, 'second_int': 42}, 'id': 'call_07bae24592ae4086abd125', 'type': 'tool_call'}])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5e3840-fdd3-4f3b-a6ae-eb3e0dea8a9e",
   "metadata": {},
   "source": [
    "## 最简单的Agent智能体\n",
    "### 你需要手动提取 tool_call 中的信息，并调用对应的函数来执行任务："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7209da7-f4ec-47a4-b5e8-7964a06be264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'first_int': 5, 'second_int': 42}\n",
      "调用工具 multiply，结果为: 210\n"
     ]
    }
   ],
   "source": [
    "# 假设 msg 是 AIMessage 对象\n",
    "for tool_call in msg.tool_calls:\n",
    "    tool_name = tool_call[\"name\"]\n",
    "    tool_args = tool_call[\"args\"]\n",
    "\n",
    "    if tool_name == \"multiply\":\n",
    "        print(tool_args)\n",
    "        result = multiply.invoke(tool_args)\n",
    "        print(f\"调用工具 {tool_name}，结果为: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22cac76-5f1f-4f74-828c-afaff6af6220",
   "metadata": {},
   "source": [
    "### 如果你希望 LLM 在某些情况下直接给出回答而不是调用工具，可以尝试修改提示或问题形式，比如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d5c5d7f-cd0f-424d-a33d-fe6583adc0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='5乘以42等于210。' additional_kwargs={} response_metadata={'model_name': 'qwen-turbo', 'finish_reason': 'stop', 'request_id': '56431ef5-2fd2-9c60-ac2e-9fa947beeb98', 'token_usage': {'input_tokens': 176, 'output_tokens': 10, 'total_tokens': 186, 'prompt_tokens_details': {'cached_tokens': 0}}} id='run--cdffff7b-ea84-4dc4-91cf-ef8a8c6caa22-0'\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models.tongyi import ChatTongyi\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(first_int: int, second_int: int) -> int:\n",
    "    \"\"\"Multiply two integers together.\"\"\"\n",
    "    return first_int * second_int\n",
    "\n",
    "\n",
    "llm = ChatTongyi(model=\"qwen-turbo\")\n",
    "\n",
    "llm_with_tools = llm.bind_tools([multiply])\n",
    "\n",
    "msg = llm_with_tools.invoke(\"5乘以42等于多少?请直接告诉我结果。\")\n",
    "\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a5e18b-fe31-42fe-883e-0b01c77b4c14",
   "metadata": {},
   "source": [
    "### 手动构造参数  \n",
    "\n",
    "即：不依赖自动解析，而是由开发者或用户自行创建和填充调用工具所需的参数。这种方式通常用于调试、自定义逻辑或在某些框架功能受限时使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a68f5327-13a3-488e-9303-660da2b6332c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'name': 'get_current_weather', 'arguments': '{\"location\": \"天津\"}'}, 'index': 0, 'id': 'call_29279f3ef98446d18496df', 'type': 'function'}]}, response_metadata={'model_name': 'qwen-turbo', 'finish_reason': 'tool_calls', 'request_id': '2d47ee7e-46bf-95b3-9743-e5833ed7cc8d', 'token_usage': {'input_tokens': 217, 'output_tokens': 20, 'total_tokens': 237, 'prompt_tokens_details': {'cached_tokens': 0}}}, id='run--a2b9012d-88b7-4f95-bfc2-535efe5b2cf6-0', tool_calls=[{'name': 'get_current_weather', 'args': {'location': '天津'}, 'id': 'call_29279f3ef98446d18496df', 'type': 'tool_call'}])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.chat_models.tongyi import ChatTongyi\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_time\",\n",
    "            \"description\": \"当你想知道现在的时间时非常有用。\",\n",
    "            \"parameters\": {},\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"当你想查询指定城市的天气时非常有用。\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"城市或县区，比如北京市、杭州市、余杭区等。\",\n",
    "                    }\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"location\"],\n",
    "        },\n",
    "    },\n",
    "]\n",
    "# 模拟工具函数的实际逻辑\n",
    "def get_current_weather(location: str):\n",
    "    # 这里你可以替换成真实的 API 调用\n",
    "    return f\"{location} 的天气是 18°C，晴天。\"\n",
    "\n",
    "def get_current_time():\n",
    "    import datetime\n",
    "    return str(datetime.datetime.now())\n",
    "    \n",
    "messages = [\n",
    "    SystemMessage(content=\"你是一位得力的助手。\"),\n",
    "    HumanMessage(content=\"天津的天气怎么样?\"),\n",
    "]\n",
    "chatLLM = ChatTongyi()\n",
    "llm_kwargs = {\"tools\": tools, \"result_format\": \"message\"}\n",
    "ai_message = chatLLM.bind(**llm_kwargs).invoke(messages)\n",
    "ai_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9170716-e348-46ad-be0d-caea2e32b61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "调用工具: get_current_weather，参数为: {'location': '天津'}\n",
      "天气结果: 天津 的天气是 18°C，晴天。\n"
     ]
    }
   ],
   "source": [
    "# 解析 tool_call\n",
    "if hasattr(ai_message, \"tool_calls\") and ai_message.tool_calls:\n",
    "    for tool_call in ai_message.tool_calls:\n",
    "        tool_name = tool_call[\"name\"]\n",
    "        tool_args = tool_call[\"args\"]\n",
    "    \n",
    "        print(f\"调用工具: {tool_name}，参数为: {tool_args}\")\n",
    "    \n",
    "        # 手动调用实际函数\n",
    "        if tool_name == \"get_current_weather\":\n",
    "            result = get_current_weather(**tool_args)\n",
    "            print(\"天气结果:\", result)\n",
    "        elif tool_name == \"get_current_time\":\n",
    "            result = get_current_time()\n",
    "            print(\"当前时间:\", result)\n",
    "else:\n",
    "    print(\"未调用任何工具，模型直接回复：\", ai_message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b750d93-0a7f-4a42-baeb-5f1c39b98319",
   "metadata": {},
   "source": [
    "### 部分模式（Partial Mode） \n",
    "该模式允许你从提供的初始文本开始，启用大模型继续生成后续内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "161beb26-f91d-4332-ab3a-e92b17edb35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='你眼中藏着星辰，却不愿为我停留？  \\n我曾在月光下旋转，像风一样自由，  \\n可如今，舞步再美，也唤不回你曾经的温柔。  \\n\\n你说我是天使，却不知我也有坠落的痛，  \\n每一次旋转，都是对过往的回眸，  \\n而你，只是站在远处，笑着看我孤独地跳。  \\n\\n难道你很想问我？  \\n可我早已把心事藏进每一个音符里，  \\n只是你，从未真正听懂。  \\n\\n我的舞步依旧优美，  \\n可心里，早已满是伤痕。', additional_kwargs={}, response_metadata={'model_name': 'qwen-turbo', 'finish_reason': 'stop', 'request_id': '85cb47a4-d2a6-9b7b-a375-8723b6864b69', 'token_usage': {'input_tokens': 46, 'output_tokens': 128, 'total_tokens': 174, 'prompt_tokens_details': {'cached_tokens': 0}}}, id='run--e2e4ee5a-056c-440c-a3cc-de29e08161c6-0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.chat_models.tongyi import ChatTongyi\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(\n",
    "        content=\"\"\"请接续“难道你很想天使问我? 我的舞步跳得可美”这句话，表达情感的复杂和作者的伤感之情。\"\"\"\n",
    "    ),\n",
    "    AIMessage(\n",
    "        content=\"为何\", additional_kwargs={\"partial\": True}\n",
    "    ),\n",
    "]\n",
    "chatLLM = ChatTongyi()\n",
    "ai_message = chatLLM.invoke(messages)\n",
    "ai_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8292ff6-6a7a-4ae5-8687-0301b92065ea",
   "metadata": {},
   "source": [
    "## 通义千问与视觉能力 \n",
    "Qwen-VL（qwen-vl-plus / qwen-vl-max）是支持图像处理的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263e8744-f87d-4e27-bcbd-51dd23b78f0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "request_id: 21eadb1e-aba5-976b-9825-da5569f77a56 \n status_code: 400 \n code: InvalidParameter \n message: <400> InternalError.Algo.InvalidParameter: Input should be a valid string: input.messages.0.content.str & Input should be a valid string: input.messages.0.content.list[union[str,function-after[post_check(), MultiModalItem]]].0.str & Input should be 'text', 'image', 'audio', 'video' or 'image_hw': input.messages.0.content.list[union[str,function-after[post_check(), MultiModalItem]]].0.function-after[post_check(), MultiModalItem].type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 27\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# image_message = {\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#     \"image\": \"https://gitee.com/hellowoody/openharmony-hint/raw/main/assets/imgs/wsl-setting.png\",\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# }\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# res = chatLLM.invoke([message])\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# res\u001b[39;00m\n\u001b[0;32m     14\u001b[0m message \u001b[38;5;241m=\u001b[39m HumanMessage(content\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     15\u001b[0m     {\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m     }\n\u001b[0;32m     25\u001b[0m ])\n\u001b[1;32m---> 27\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mchatLLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(res\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\langchain_core\\language_models\\chat_models.py:378\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    368\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    374\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    375\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    377\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m--> 378\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    379\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    380\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    381\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    382\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    383\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    384\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    385\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    386\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    387\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    388\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\langchain_core\\language_models\\chat_models.py:963\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    954\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    956\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    960\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    961\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    962\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 963\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\langchain_core\\language_models\\chat_models.py:782\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    781\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 782\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    783\u001b[0m                 m,\n\u001b[0;32m    784\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    785\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    786\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    787\u001b[0m             )\n\u001b[0;32m    788\u001b[0m         )\n\u001b[0;32m    789\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\langchain_core\\language_models\\chat_models.py:1028\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1026\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1028\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m   1029\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   1030\u001b[0m     )\n\u001b[0;32m   1031\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1032\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\langchain-env\\lib\\site-packages\\langchain_community\\chat_models\\tongyi.py:669\u001b[0m, in \u001b[0;36mChatTongyi._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    666\u001b[0m     params: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invocation_params(\n\u001b[0;32m    667\u001b[0m         messages\u001b[38;5;241m=\u001b[39mmessages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    668\u001b[0m     )\n\u001b[1;32m--> 669\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompletion_with_retry(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    670\u001b[0m     generations\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m    671\u001b[0m         ChatGeneration(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_chat_generation_from_qwen_resp(resp))\n\u001b[0;32m    672\u001b[0m     )\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ChatResult(\n\u001b[0;32m    674\u001b[0m     generations\u001b[38;5;241m=\u001b[39mgenerations,\n\u001b[0;32m    675\u001b[0m     llm_output\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m    676\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name,\n\u001b[0;32m    677\u001b[0m     },\n\u001b[0;32m    678\u001b[0m )\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\langchain-env\\lib\\site-packages\\langchain_community\\chat_models\\tongyi.py:540\u001b[0m, in \u001b[0;36mChatTongyi.completion_with_retry\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    537\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcall(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m check_response(resp)\n\u001b[1;32m--> 540\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _completion_with_retry(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tenacity\\__init__.py:338\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    336\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    337\u001b[0m wrapped_f\u001b[38;5;241m.\u001b[39mstatistics \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mstatistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m--> 338\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m copy(f, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tenacity\\__init__.py:477\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 477\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    479\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tenacity\\__init__.py:378\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    376\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[1;32m--> 378\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tenacity\\__init__.py:400\u001b[0m, in \u001b[0;36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[1;34m(rs)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetryCallState\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    399\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mis_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mretry_run_result):\n\u001b[1;32m--> 400\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutcome\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    401\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\langchain-env\\lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\langchain-env\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tenacity\\__init__.py:480\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 480\u001b[0m         result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    481\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[0;32m    482\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\langchain-env\\lib\\site-packages\\langchain_community\\chat_models\\tongyi.py:538\u001b[0m, in \u001b[0;36mChatTongyi.completion_with_retry.<locals>._completion_with_retry\u001b[1;34m(**_kwargs)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    537\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcall(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n\u001b[1;32m--> 538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresp\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\langchain-env\\lib\\site-packages\\langchain_community\\llms\\tongyi.py:61\u001b[0m, in \u001b[0;36mcheck_response\u001b[1;34m(resp)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m resp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m400\u001b[39m, \u001b[38;5;241m401\u001b[39m]:\n\u001b[1;32m---> 61\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrequest_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     63\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus_code: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus_code\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     64\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m message: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     65\u001b[0m     )\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHTTP error occurred: status_code: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus_code\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     69\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m message: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     70\u001b[0m         response\u001b[38;5;241m=\u001b[39mresp,\n\u001b[0;32m     71\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: request_id: 21eadb1e-aba5-976b-9825-da5569f77a56 \n status_code: 400 \n code: InvalidParameter \n message: <400> InternalError.Algo.InvalidParameter: Input should be a valid string: input.messages.0.content.str & Input should be a valid string: input.messages.0.content.list[union[str,function-after[post_check(), MultiModalItem]]].0.str & Input should be 'text', 'image', 'audio', 'video' or 'image_hw': input.messages.0.content.list[union[str,function-after[post_check(), MultiModalItem]]].0.function-after[post_check(), MultiModalItem].type"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatTongyi\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "chatLLM = ChatTongyi(model_name=\"qwen-vl-max\")\n",
    "image_message = {\n",
    "    \"image\": \"https://gitee.com/hellowoody/openharmony-hint/raw/main/assets/imgs/wsl-setting.png\",\n",
    "}\n",
    "text_message = {\n",
    "    \"text\": \"描述这张图\",\n",
    "}\n",
    "message = HumanMessage(content=[text_message, image_message])\n",
    "res = chatLLM.invoke([message])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf7facd1-3f72-471a-9287-ed72215714f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'generator' object has no attribute 'content'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'generator' object has no attribute 'content'"
     ]
    }
   ],
   "source": [
    "print(res.content[0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0bc5fc4b-4536-4fe9-8c5d-b9321771b028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatTongyi(client=<class 'dashscope.aigc.multimodal_conversation.MultiModalConversation'>, model_name='qwen-vl-max', model_kwargs={}, dashscope_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2c3ab1-414d-40a3-9103-ebc79b2bce86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
